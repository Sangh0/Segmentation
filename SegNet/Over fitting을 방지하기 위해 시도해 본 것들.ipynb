{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82db741b",
   "metadata": {},
   "source": [
    "# Over-fitting을 방지하기 위해서 한 일들  \n",
    "- SegNet을 CamVid data set을 가지고 구현하면서 겪은 골치 아픈 일이 over fitting 현상이다  \n",
    "- over fitting을 방지하기 위해 내가 어떤 코드를 작성했고 어떤 판단을 내렸는지 기록한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4563d",
   "metadata": {},
   "source": [
    "- 오버피팅을 방지할 수 있는 방법들은 다음과 같다    \n",
    "    - 1. Batch Normalization  \n",
    "    - 2. Drop out  \n",
    "    - 3. weight initialize  \n",
    "    - 4. 모델의 레이어를 조금 더 간단하게 구성  \n",
    "    - 5. Early Stopping  \n",
    "    - 6. Image Data Augmentation  \n",
    "    - 7. Train data set 추가\n",
    "    - 이 외에도 다양한 방법들이 존재한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d474e",
   "metadata": {},
   "source": [
    "### 1. Add Batch Normalization Layer  \n",
    "- Batch Norm이란?  \n",
    "    - 모델을 훈련할 때 메모리를 효율적으로 사용하기 위해 이미지를 batch 별로 나눠서 훈련을 한다  \n",
    "    - batch norm이란 이러한 batch의 평균과 분산을 이용해 정규화를 시키는 방법이다  \n",
    "    - 다른 정규화 기법으로 instance norm, layer norm, group norm 등이 있다\n",
    "- 이는 이미 논문에서도 Convolution Block 구성에서 Conv + BN + ReLU로 되어있고  \n",
    "- SegNet을 구현하는 과정에서도 BN을 사용했으므로 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896808d8",
   "metadata": {},
   "source": [
    "### 2. Add Drop Out Layer  \n",
    "- Drop out이란?  \n",
    "    - Drop out은 레이어에서 다음 레이어로 weight를 0으로 전달하는 것이다  \n",
    "    - 즉, 다음 레이어에 영향을 주지 않도록 하는 것이다\n",
    "- Drop out layer를 적용해 성능이 어떤지 실험해보기 전에  \n",
    "- Drop out layer를 추가하는 것에 대한 나의 생각을 적어본다  \n",
    "    - 개인적으로 생각하기엔 Segmentation task에서 model을 구성할 때 drop out layer를 적용하는 것은 큰 리스크가 있다고 생각한다  \n",
    "    - Segmentation에서는 이미지의 pixel 하나 하나가 모두 중요한 정보라고 생각한다  \n",
    "    - 특히나 CamVid data set의 경우 object가 작은 pedestrian이나 bicyclist같은 경우 segmentation을 수행하지 못하면 이 모델을 자율 주행의 목적으로 사용한다고 한다면 굉장히 위험한 일이다  \n",
    "    - 그래서 이러한 상황에서 drop out layer를 추가한다면 중요한 feature의 weight를 전달하지 못하는 일이 생길 수도 있다고 생각한다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a569cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder block module using pre-trained vgg16\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, index, dropout=True):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # build encoder network (Conv + BN + ReLU)\n",
    "        block = [\n",
    "            vgg16.features[index],\n",
    "            nn.BatchNorm2d(vgg16.features[index].out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if dropout:\n",
    "            block.append(nn.Dropout(0.2))\n",
    "        self.block = nn.Sequential(*block)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "# define encoder block module\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # build decoder network (Conv + BN + ReLU)\n",
    "        block = [\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if dropout:\n",
    "            block.append(nn.Dropout(0.2))\n",
    "        self.block = nn.Sequential(*block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f57e89",
   "metadata": {},
   "source": [
    "**Result**\n",
    "- Drop out layer를 추가해봤다  \n",
    "- 이때 Encoder Network의 첫 번째 Block과 Decoder의 마지막 Block에는 drop out을 적용하지 않았다  \n",
    "- 적어도 input으로 들어오는 이미지의 모든 pixel은 feature로 전달 받아야 Segmentation을 잘 수행한다고 판단했다  \n",
    "- 결과적으로 보면 Segmentation을 잘 수행하지 못했다  \n",
    "- 그래서 Drop out layer를 적용하는 것은 X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74b24f",
   "metadata": {},
   "source": [
    "### 3. weight initialization  \n",
    "- 딥러닝 학습에서는 가중치가 매우 중요하다  \n",
    "- 가중치 하나로 인해 모델의 결과가 완전히 달라질 수 있다  \n",
    "- 그래서 특정 분포나 Xavier, Kaiming, LeCun 등 다른 초기화 방법을 따라 가중치를 초기화 시켜 학습에 안정이 되게끔 해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71383151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define encoder block module using pre-trained vgg16\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, index):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        # build encoder network (Conv + BN + ReLU)\n",
    "        self.block = nn.Sequential(\n",
    "            vgg16.features[index],\n",
    "            nn.BatchNorm2d(vgg16.features[index].out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self._initialize_weights_()                    \n",
    "        \n",
    "    # he normal initialization\n",
    "    def _initialize_weights_(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "# define encoder block module\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # build decoder network (Conv + BN + ReLU)\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self._initialize_weights_()                    \n",
    "        \n",
    "    # he normal initialization\n",
    "    def _initialize_weights_(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6470c9c",
   "metadata": {},
   "source": [
    "**Result**  \n",
    "- weight들을 초기화하나 안하나 output은 별 차이가 없는 것 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023c11b",
   "metadata": {},
   "source": [
    "### 4. 모델의 레이어를 조금 더 간단하게 구성  \n",
    "- 내가 구축한 SegNet은 5개의 Encoder Network, 이와 대칭인 5개의 Decoder Network로 이루어져 있다  \n",
    "- 조금 더 간단하게 구성해 4개의 Encoder와 Decoder 혹은 3개로 구성했다  \n",
    "\n",
    "**Result**  \n",
    "- 4개의 Encoder Network, 이와 대칭인 4개의 Decoder Network  \n",
    "- 그리고 3개의 Encoder Network, 이와 대칭인 3개의 Decoder Network 두 가지 구성으로 실험을 해 본 결과  \n",
    "- 5개의 네트워크로 구성한 것과는 별 차이가 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708ee17",
   "metadata": {},
   "source": [
    "### 5. Early Stopping  \n",
    "- early stopping은 over-fitting을 방지할 수 있는 가장 편리하면서도 쉬운 방법이라 생각한다  \n",
    "- patience의 value를 지정해 해당 value만큼 validation loss가 개선되지 않을 경우 학습을 종료시켜버리는 방식이다  \n",
    "- Train data가 학습되기도 전에 validation loss가 증가해서 early stopping되는 경우가 많았다  \n",
    "- patience는 현재 20으로 설정했지만 40정도로 더 크게 잡아야 하나 생각한다  \n",
    "- 어떻게 해결해야 할까,,,  \n",
    "\n",
    "- 사실 early stopping은 오버피팅이 되지 않도록 강제로 종료하는 것이지  \n",
    "- 오버피팅 문제를 해결해주는건 아니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set early stopping to check over fitting of model\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.3f} --> {val_loss:.3f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82213278",
   "metadata": {},
   "source": [
    "### 6. Data Augmentation  \n",
    "- Data Augmentation은 이미지 데이터를 좌우 반전, 상하 반전, 회전 등 다양한 변환을 적용해 이미지 데이터를 증강시키는 기법이다  \n",
    "- 개인적인 생각으로는 Segmentation task에는 data augmentation이 적절치 않다고 생각한다  \n",
    "- 이미지 pixel 하나 하나를 class 별로 분류해야 하는 작업인데 augmentation을 통해 모델을 훈련시키는 과정에서 weight들이 잘못 훈련될 수 있기 때문이다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_ = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.RandomAffine(30),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomRotation(30, expand=False),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25cc42",
   "metadata": {},
   "source": [
    "**Result**\n",
    "- Data Augmentation의 결과 역시 좋지 않다  \n",
    "- 따라서 Segmentation task에는 Augmentation이 좋은 방법은 아니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8bf93",
   "metadata": {},
   "source": [
    "### 7. Train data 추가  \n",
    "- 현재 쓰고 있는 CamVid data set은 kaggle에서 얻어온 데이터다  \n",
    "- 이는 train은 367장, valid는 101장, test는 233장으로 구성되어 있다  \n",
    "- 이 데이터들을 각각 train, valid, test 그대로 사용을 했으나  \n",
    "- valid loss가 0.5에서 줄어들지 않고 mIoU score는 0.4에서 증가하지 않았다  \n",
    "- 그래서 이 3가지 data set을 합쳐 shuffling한 후  \n",
    "- 다시 train은 500장, valid는 100장, test는 101장으로 사용해본 결과  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 합치기 (총 701장)\n",
    "data_images = np.concatenate((train_image,valid_image,test_image), axis=0)\n",
    "data_labels = np.concatenate((train_label,valid_label,test_label), axis=0)\n",
    "\n",
    "# shuffling\n",
    "idx = np.arange(len(data_images))\n",
    "np.random.shuffle(idx)\n",
    "shuffled_images = data_images[idx]\n",
    "shuffled_labels = data_labels[idx]\n",
    "\n",
    "# divide train, valid and test data set\n",
    "# train data: 500장\n",
    "train_image = shuffled_images[:500]\n",
    "train_label = shuffled_labels[:500]\n",
    "# valid data: 100장\n",
    "valid_image = shuffled_images[500:600]\n",
    "valid_label = shuffled_labels[500:600]\n",
    "# test data: 101장\n",
    "test_image = shuffled_images[600:]\n",
    "test_label = shuffled_labels[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e23d1",
   "metadata": {},
   "source": [
    "**Result**  \n",
    "- valid loss가 가끔 0.3 후반대가 나올 때도 있고 valid mIoU도 0.5 이상으로 증가한 것을 확인했다  \n",
    "- 아무래도 train data set을 조금 더 많은 데이터로 훈련시켜야 학습이 잘 되는 듯 하다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
