{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70bfb54",
   "metadata": {},
   "source": [
    "# U-Net 논문 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3db11",
   "metadata": {},
   "source": [
    "## Patch Learning\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/99304833605C18F313?original\">  \n",
    "\n",
    "- U-Net은 중복되지 않은 patch를 이용해 학습  \n",
    "- 이는 patch가 겹칠 때 불필요한 연산이 늘어나는 것을 방지하기 위함  \n",
    "- 또한 속도도 느리고 시간도 오래 걸림  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e258b94",
   "metadata": {},
   "source": [
    "## Overlap-tile  \n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/99269846605C18F311?original\">  \n",
    "\n",
    "- 위에서 말했듯이 patchwise 학습을 이용한다    \n",
    "- 높은 해상도의 이미지를 출력하기 위해 overlap-tile을 이용한다    \n",
    "- U-Net의 down-sampling 과정에서 padding을 사용하지 않기 때문에 output의 사이즈가 input보다 작음  \n",
    "- 이 논문에서는 mirroring padding이라는 것을 이용함  \n",
    "- patch 단위로 잘라 네트워크에 입력하는데 노란색 영역을 기준으로 사이드에 이미지를 symmetric해서 채움  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ed2dd",
   "metadata": {},
   "source": [
    "## U-Net architecture\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/997C3A42605C18F311?original\">  \n",
    "\n",
    "- U-Net architecture는 크게 Contracting Path와 Expansive Path로 나뉘어짐  \n",
    "- 1. Contractign Path  \n",
    "    - 전형적인 convolution network 구조  \n",
    "    - 두 번의 3x3 convolution을 반복 수행하며 padding을 사용하지 않음  \n",
    "    - 활성화 함수로는 ReLU를 사용  \n",
    "    - 2x2 max-pooling과 stride 2를 사용  \n",
    "    - down-sampling 과정에서 feature channel이 2배씩 늘어남  \n",
    "- 2. Expansive Path  \n",
    "    - 2x2 up-convolution을 사용  \n",
    "    - up-sampling 과정에서 feature channel이 2배씩 줄어듦  \n",
    "    - contracting path에서 max-pooling 되기 전의 feature map의 테두리 부분을 사이즈에 맞게 crop하여 up-convolution할 때 concatenation을 진행  \n",
    "    - 두 번의 3x3 convolution을 반복  \n",
    "    - 활성화 함수로는 ReLU를 사용  \n",
    "- 3. Final Layer  \n",
    "    - 마지막 layer에서는 1x1 convolution을 사용해 2개의 클래스로 분류  \n",
    "    - object와 background 두 개의 클래스를 구분하기 위해 2개의 클래스로 지정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe5bfc",
   "metadata": {},
   "source": [
    "## Optimizer And Loss  \n",
    "- optimizer로는 stochastic gradient descent  \n",
    "- 이때 momentum의 값을 0.99를 줘서 이전의 값들을 많이 반영하게 함  \n",
    "\n",
    "**Softmax function**\n",
    "<img src = \"https://miro.medium.com/max/594/0*qLhMYSprvsobuot1.png\">  \n",
    "**Cross Entropy Loss with $w(x)$ function**  \n",
    "<img src = \"https://miro.medium.com/max/700/0*8kUKwV1z9DWX9B0k.png\">  \n",
    "<img src = \"https://miro.medium.com/max/700/0*s2oMdVI8w1ms9N0l.png\">  \n",
    "- 이를 논문에서는 Energy function이라고 정의함  \n",
    "- $d_1$과 $d_2$는 $x$에서 가장 가까운 세포까지의 거리, 두 번째로 가까운 세포까지의 거리를 계산하는 함수  \n",
    "- 즉, $x$는 세포 사이에 존재하는 픽셀이며 두 세포 사이의 간격이 좁을수록 weight를 큰 값으로 부여한다  \n",
    "- 이를 다음 그림으로 나타냄  \n",
    "\n",
    "<img src = \"https://t1.daumcdn.net/cfile/tistory/997DE543605C18F311?original\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe0d20",
   "metadata": {},
   "source": [
    "## Data Augmentation  \n",
    "- U-Net은 적은 데이터로 충분히 학습하기 위해 data augmentation을 사용함  \n",
    "- 일반적인 목적이 아니라 biomedical에서 쓰이기 위한 목적으로 만들어졌으므로 data augmentation이 나쁘지 않은 성능을 가져올 수 있다고 판단  \n",
    "- 또한 elastic deformation을 통해 세포가 변형되는 것까지 augmentation을 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ba1c0",
   "metadata": {},
   "source": [
    "## Code Implementation Pipeline  \n",
    "- 1. data augmentation을 진행 (elastic deformation을 포함)  \n",
    "- 2. U-Net architecture와 똑같은 네트워크 생성  \n",
    "- 3. Momentum 및 Energy function 정의  \n",
    "- 4. 사용자 정의 모델 학습으로 훈련 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a7891",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
