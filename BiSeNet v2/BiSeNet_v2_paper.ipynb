{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678e8223",
   "metadata": {},
   "source": [
    "# BiSeNet v2: Bilateral Network with Guided Aggregation for Real-time Semantic Segmentation  \n",
    "- 논문 리뷰  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4696700",
   "metadata": {},
   "source": [
    "## Abstract  \n",
    "- low-level detail과 high-level semantic 모두 semantic segmentation task에서 필수적인 요소임  \n",
    "- 현재 모델들은 inference speed를 위해 low-level detail을 희생함  \n",
    "- 우리는 spatial detail과 categorical semantic을 따로 분리해 취급한다  \n",
    "\n",
    "**Architecture**  \n",
    "- 1. Detail Branch \n",
    "    - low level detail을 capture  \n",
    "    - high resolution feature representation을 생성하기 위해 wide channels과 shallow layers로 구성  \n",
    "    \n",
    "- 2. Semantic Branch  \n",
    "    - high level semantic context를 얻음   \n",
    "    - narrow channels와 deep layers로 구성  \n",
    "    \n",
    "- 3. Guided Aggregation Layer  \n",
    "    - mutual connection을 강화하고 feature representation을 결합  \n",
    "    \n",
    "- BiSeNet v2는 Cityscapes data set에서 156 FPS와 72.6% mIoU의 SOTA를 달성함  \n",
    "\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure1.JPG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cc2ab",
   "metadata": {},
   "source": [
    "## Introduction   \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure2.JPG?raw=true\">  \n",
    "\n",
    "- semantic segmentation에서 높은 정확도를 달성하는 것은 backbone network와 관련이 있음  \n",
    "- 크게 2개의 babkbone network 형태가 있다  \n",
    "    - 1. Dilation backbone  \n",
    "        - 이는 down sampling 연산을 제거하고 해당 filter kernel을 up sampling을 수행  \n",
    "        - high resolution feature representation을 얻음  \n",
    "        \n",
    "    - 2. Encoder-Decoder backbone  \n",
    "        - 일반적인 backbone network   \n",
    "        - top-down과 skip connection을 이용해 decoder part에서 high resolution feature representation을 회복  \n",
    "        \n",
    "- 그러나 위의 두 backbone architecture는 inference speed가 느리며 computing cost가 많이 든다  \n",
    "- real-time semantic segmentation은 빠른 inference 속도를 필요로 함  \n",
    "- 최근 모델은 이를 위해 2가지 접근법을 사용함  \n",
    "    - 1. Input Restricting  \n",
    "        - Input 이미지가 작을수록 computing cost가 적어짐  \n",
    "    - 2. Channel Pruning  \n",
    "        - inference 속도를 가속화하며 초기 stage에 channel pruning을 하면 더 빨라짐   \n",
    "        \n",
    "- 위의 두 방법은 inference 속도를 어느 정도 개선하지만 low-level detail이 부족함  \n",
    "- 따라서 높은 효율성과 정확도를 위해 specific architecture를 활용하는 것이 중요함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd95c15",
   "metadata": {},
   "source": [
    "- 일반적인 semantic segmentation은 deep하고 wide한 network로 구성됨  \n",
    "- 이를 이용해 low-level, high-level information 모두를 encoding을 수행함  \n",
    "- 그러나 본 논문은 spatial detail과 semantic categorical을 별도로 처리해 성능을 높임  \n",
    "- 즉, two-pathway로 구성된 BiSeNet v2를 제안한다  \n",
    "- Detail Branch는 wide channels과 shallow layers로 spatial detail을 capture하기 위해 설계됨  \n",
    "- Semantic Branch는 narrow한 channels과 deep한 layers로 categorical semantic을 추출하기 위해 설계됨  \n",
    "- Semantic Branch에서는 semantic context를 capture하기 위해 큰 receptive field를 필요로 함  \n",
    "- detail information은 Detail Branch에서 얻음  \n",
    "- 따라서 Semantic Branch는 더 적은 channel과 빠른 down-sampling을 수행해 매우 가벼움  \n",
    "- 이 후, 두 개의 feature representation을 합침  \n",
    "- 이때 효율적으로 합치기 위해 **Guided Aggregation Layer**를 제안함  \n",
    "- 또한 inference 성능 향상을 위해 **booster**를 제안함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf1c80",
   "metadata": {},
   "source": [
    "## Core Concepts of BiSeNet v2  \n",
    "- 본 논문의 architecture는 크게 Detail Branch, Semantic Branch, Aggregation Layer로 구성돼 있음    \n",
    "\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure3.JPG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5e6dd",
   "metadata": {},
   "source": [
    "## Detail Branch  \n",
    "- Detail Branch는 큰 채널 capacity과 풍부한 spatial detailed information을 필요로 함  \n",
    "- 중요한 concept는 spatial detail을 위해 wide한 channels과 shallow한 layers를 사용하는 것  \n",
    "- Detail Branch의 feature representation은 큰 spatial size와 wide한 channels를 갖고 있음  \n",
    "- 따라서 information이 충분하므로 residual connection을 적용하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e271da0",
   "metadata": {},
   "source": [
    "## Semantic Branch  \n",
    "- Semantic Branch는 low channels capacity를 갖고 있음  \n",
    "- 본 논문에서 어떤 실험을 했는데 각 Branch의 채널 수가 일정 비율의 값을 가지게 해봤다  \n",
    "- 즉, Semantic Branch가 Detail Branch의 채널의 $\\lambda$배가 되도록 해서 lightweight가 되게 함  \n",
    "- 이때, $\\lambda<1$이다  \n",
    "- Semantic Branch는 feature representation의 level을 증가하고 receptive field를 확대하기 위해 fast down sampling을 적용   \n",
    "- high level semantic은 large receptive field를 필요로 하므로 GAP를 적용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea6a59",
   "metadata": {},
   "source": [
    "## Aggregation Layer  \n",
    "- 위의 두 Branch의 feature representation은 서로 상호 보완적임  \n",
    "- Aggregation Layer는 두 feature를 합치기 위해 설계되었음  \n",
    "- fast down sampling 때문에 Semantic Branch의 output dimension이 Detail Branch의 output dimension보다 작음  \n",
    "- 그래서 Semantic Branch의 output feature map을 up sampling을 수행해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80634b67",
   "metadata": {},
   "source": [
    "## Architecture of BiSeNet v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af2862",
   "metadata": {},
   "source": [
    "### Detail Branch  \n",
    "- Detail Branch는 3 stage로 구성됨  \n",
    "- 각 stage는 Conv + BN + ReLU로 구성됨    \n",
    "- first stage의 경우, stride 2 Conv layer를 사용  \n",
    "- output size는 input size의 1/8  \n",
    "- VGG의 구조를 따름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e2255",
   "metadata": {},
   "source": [
    "### Semantic Branch  \n",
    "- large receptive field와 효율적인 연산을 위해서 lightweight model을 사용  \n",
    "- 예를 들면 Xception, MobileNet, ShuffleNet  \n",
    "\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure4.JPG?raw=true\">\n",
    "\n",
    "**Stem Block**  \n",
    "- Semantic Branch의 first stage에 해당  \n",
    "- 2개의 다른 방식으로 down sampling을 수행  \n",
    "- 이후 두 Branch의 output을 합친다  \n",
    "- Stem Block는 연산 비용이 효율적임  \n",
    "\n",
    "**Context Embedding Block**  \n",
    "- Semantic Branch는 high level semantic을 capture하기 위해서 large receptive filed를 필요로 함  \n",
    "- global contexual information을 효율적으로 embedding하기 위해 GAP와 resudial connection을 사용함    \n",
    "\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure5.JPG?raw=true\">\n",
    "\n",
    "**Gather-and-Expansion Layer**  \n",
    "- depth-wise convolution을 이용함  \n",
    "- 마지막에 1x1 conv를 이용해 depth-wise conv의 output을 projection시킴  \n",
    "- 기존 MobileNet v2 구조와 달리 3x3 conv layer를 하나 더 사용해 더 좋은 feature quality를 얻음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a6b25",
   "metadata": {},
   "source": [
    "### Bilateral Guided Aggregation  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure6.JPG?raw=true\">\n",
    "\n",
    "- 서로 다른 feature를 합칠 때 여러 방법으로 합치게 됨 (sum, concat 등)  \n",
    "- 그러나 Detail Branch와 Semantic Branch의 output은 서로 다른 feature level을 가짐  \n",
    "- 따라서 단순히 합치기만 한다면 좋지 않은 성능이 나올 것임   \n",
    "- 그래서 두 Branch의 output을 결합하는 Guided Aggregation Layer를 제안한다  \n",
    "- 이는 Semantic Branch의 contextual한 정보를 이용해 Detail Branch의 feature reponse를 guide한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52815b3f",
   "metadata": {},
   "source": [
    "### Booster Training Strategy  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure7.JPG?raw=true\">\n",
    "\n",
    "- Segmentation accuracy를 개선시키기 위해 booster training을 제안한다  \n",
    "- 이는 training 단계에서 feature representation을 향상시키며  \n",
    "- inference 단계에서 효율을 높일 수 있다  \n",
    "- 따라서 계산 복잡도가 거의 증가하지 않음  \n",
    "- 이는 Semantic Branch의 사이사이에 삽입해서 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16252553",
   "metadata": {},
   "source": [
    "## Experimental Results  \n",
    "- Dataset  \n",
    "    - Cityscapes  \n",
    "        - train: 2975, valid: 500, test: 1525  \n",
    "        - class: 30\n",
    "        - resolution: 2048 x 1024\n",
    "    - CamVid  \n",
    "        - train: 367, valid: 101, test: 233  \n",
    "        - class: 11  \n",
    "        - resolution: 960 x 720  \n",
    "    - COCO  \n",
    "        - train: 9K, test: 1K  \n",
    "        - class: 91  \n",
    "        - resolution : 640 x 640\n",
    "        \n",
    "- Training  \n",
    "    - init weight : kaiming normal  \n",
    "    - optimizer : SGD momentum 0.9  \n",
    "    - batch size : 16  \n",
    "    - weight decay : 0.0005 (in Cityscapes and CamVid), 0.0001 (in COCO)  \n",
    "    - learning rate : 5e-2  \n",
    "    - lr scheduler : poly learning rate strategy  $\\left(1-\\frac{iter}{iters_{max}}\\right)^{power}$ with power 0.9  \n",
    "    - iteration : Cityscapes (150K), CamVid (10K), COCO (20K)  \n",
    "    - data augmentation : random horizontally flip, randomly scale (0.75, 1, 1.25, 1.5, 1.75, 2.0), randomly crop (fixed 2048x1024)  \n",
    "    \n",
    "- Inference  \n",
    "    - metric : mean IoU (Cityscapes and CamVid), pixel accuracy (COCO)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913751a",
   "metadata": {},
   "source": [
    "### Ablative Evaluation on Cityscapes  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure8.JPG?raw=true\">    \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table2.JPG?raw=true\">   \n",
    "\n",
    "- Semantic과 Detain Branch 두 개를 같이 쓰는 것이 성능이 더 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147a6d5",
   "metadata": {},
   "source": [
    "### Aggregation methods  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure9.JPG?raw=true\">    \n",
    "   \n",
    "   \n",
    "- Detail Branch는 spatial한 정보를 제공하며   \n",
    "- Semantic Branch는 semantic context를 capture한다  \n",
    "- 두 Branch를 같이 사용하게 되면 더욱 세밀한 segmentation을 수행할 수 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898c457",
   "metadata": {},
   "source": [
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table3.JPG?raw=true\">\n",
    "\n",
    "\n",
    "### Channel capacity of Semantic Branch  \n",
    "- Semantic Branch의 각 채널은 Detail Branch 채널의 $1/\\lambda$만큼의 수를 가짐  \n",
    "- $\\lambda=4$가 가장 성능이 좋음  \n",
    "\n",
    "### Expansion ratio of GE layer  \n",
    "- expasion ratio $\\epsilon$은 GE Layer의 output dimension을 결정함  \n",
    "- $\\epsilon=1$인 경우 baseline보다 mIoU가 4% 이상 개선됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1ec47",
   "metadata": {},
   "source": [
    "### Block design of of Semantic Branch  \n",
    "  \n",
    "\n",
    "- main improvements  \n",
    "    - 1. MobileNet v2의 inverted bottleneck에서 1개의 point wise conv 대신 3x3 conv 하나를 Gather Layer로 채택  \n",
    "    - 2. stride = 2인 경우, 5x5 conv를 한 번 수행하는 것보다 3x3 conv을 두 번 수행하는 것이 더 효율적  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91338634",
   "metadata": {},
   "source": [
    "### Booster training strategy  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/figure7.JPG?raw=true\">\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table4.JPG?raw=true\">\n",
    "\n",
    "- 위 그림처럼 Semantic Branch를 훈련할 때는 사이사이에 Booster을 넣고 inference할 때는 폐기  \n",
    "- Booster 훈련은 정확도를 향상시킴  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203369f",
   "metadata": {},
   "source": [
    "### Generalization to large models  \n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table5.JPG?raw=true\">\n",
    "\n",
    "- 기존 BiSeNet v2에서 모델을 wider or deeper하게 만들어 실험  \n",
    "- $\\alpha=2$, $d=3$만큼 더 wide하고 deep한 BiSeNet v2 Large 모델을 만듦  \n",
    "- 그 결과 FPS는 낮아졌지만 정확도가 더 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab64e0bb",
   "metadata": {},
   "source": [
    "## Comparing on dataset  \n",
    "**Cityscapes data set**\n",
    "\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table7.JPG?raw=true\"> \n",
    "\n",
    "**CamVid data set**\n",
    "<img src = \"https://github.com/Sangh0/Segmentation/blob/main/BiSeNet%20v2/figure/table8.JPG?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603bf2a",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "- BiSeNet v2는 low-level detail과 high-level semantic 둘 다 뽑아낼 수 있는 모델임  \n",
    "- 이 모델의 architecture는 일반적이며 범용성이 굉장히 넓음  \n",
    "- 이 모델은 segmentation accuracy와 inference speed의 trade-off를 적절히 극복함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
